{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'full_half_conversion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8073b77b2eee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfull_half_conversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'full_half_conversion'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import codecs\n",
    "from full_half_conversion import *\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　関数　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCSVFiles():\n",
    "    files = os.listdir(r_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for t in  files:\n",
    "        if(t[-4:] == '.csv' and (t[:2].upper() == \"NG\" or t[:2].upper() == \"OK\")):\n",
    "             csv_files.append(t)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSAExtractedFiles():\n",
    "    files = os.listdir(w_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if(file.find(\".csv\") != -1 and file.startswith(\"SA_Sub_\")):\n",
    "             csv_files.append(file)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAssyExtractedFiles():\n",
    "    files = os.listdir(w_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if(file.find(\".csv\") != -1 and file.startswith(\"Assy_Sub_\")):\n",
    "             csv_files.append(file)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAssyWithGelExtractedFiles():\n",
    "    files = os.listdir(w_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if(file.find(\".csv\") != -1 and file.startswith(\"AssyWithGel_\")):\n",
    "             csv_files.append(file)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllExtractedFiles():\n",
    "    files = os.listdir(w_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if(file.find(\".csv\") != -1 and file.find(\"Sub_\") != -1):\n",
    "             csv_files.append(file)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateSADefectiveRatio():\n",
    "    \n",
    "    #不良率ファイル読み込み\n",
    "    dr_path = os.path.join(\"..\", \"＜更新＞サブアッシー不良率.xlsx\")    \n",
    "    df = pd.read_excel(dr_path, encoding=\"SHIFT-JIS\", skiprows=[0,1], usecols=[4,5,6,7,9,10,11,12], dtype = {\"製番\":\"object\"}, sheet_name=0)\n",
    "        \n",
    "    #列名をリネーム\n",
    "    new_cols = [\"Lot\", \"WorkNum\", \"DefectNum\", \"DefectRatio\", \"sub1\", \"sub2\", \"sub3\", \"sub4\"]\n",
    "    df.columns = new_cols\n",
    "    \n",
    "    #いらんとこドロップ\n",
    "    ks = df.apply(lambda s: s.astype(str).str.contains(\"要確認\", na=False))\n",
    "    df = df.mask(ks)\n",
    "    df = df.dropna(subset=[\"WorkNum\", \"DefectNum\", \"sub1\"])\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    #全角を半角に\n",
    "    for i in np.arange(df.shape[0]):\n",
    "        for j in [1,2,3,4]:\n",
    "            if not pd.isnull(df.loc[i, \"sub%s\" %j]):\n",
    "                df.loc[i, \"sub%s\" %j] = zen2han(df.loc[i, \"sub%s\" %j])\n",
    "    \n",
    "    #その他\n",
    "    #本当は，./で区切られて1セルに複数ロットあるのとか，E07xxのような文字列入ってるのとかあるけど，今回のロットには関係ないので省略\n",
    "    #これは入力側で頑張ってもらいたい．めんどい\n",
    "    \n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(\"..\", \"SA_DefectiveRatio.csv\"), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-1559c8b0715c>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-1559c8b0715c>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    \"\"}\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#未完成　やってられん\n",
    "def CreateSubstrateSpecs():\n",
    "    dr_path = os.path.join(\"..\", \"AssemblyData\", \"Part_Spec\", \"substrate_spec.xlsx\")\n",
    "    re_cols = {\"京セラ\\n出荷日\":\"delivery_date\", \"京セラ手配No\":\"logis_no\", \"出荷\\nﾛｯﾄNo\":\"lot_no\", \"セラミック\\nロット\":\"ceramic_lot\",\n",
    "               \"寸法\\nランク\":\"sz_rank\", \"1次+2次Niめっき厚み[μm]\":\"Ni_thick[um]\", \"Pdめっき厚み[μm]\":\"Pd_thick[um]\",\n",
    "               \"Auめっき厚み[μm]\":\"Au_thick[um]\", \"Ni/Pd/Auめっき\":\"Ni/Pd/Au_plating\", \"Pdめっき\":\"Pd_plating\", \"Auめっき\":\"Au_plating\",\n",
    "               \"電気伝導度（水洗）[μS/cm]\":\"elec_conduct_cw[uS/cm]\", \"電気伝導度（湯煎）[μS/cm]\":\"elec_conduct_hw[uS/cm]\",\n",
    "               \"\"}\n",
    "    \n",
    "    \n",
    "    temp = pd.read_excel(dr_path, encoding=\"SHIFT-JIS\", skiprows=7, header=None, sheet_name=0)\n",
    "    temp = temp.drop(0, axis=1)\n",
    "    header = temp[:2]\n",
    "    df = temp[2:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    header = header.fillna(method=\"ffill\", axis=1)\n",
    "    \n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    \n",
    "    print(header.head())\n",
    "    print(df.head())\n",
    "    \n",
    "#CreateSubstrateSpecs()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#時間差をsecで出力\n",
    "def CalcDeltaSeconds(t):\n",
    "    t1, t2 = t\n",
    "    delta = t2 - t1\n",
    "    \n",
    "    return delta.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1セル内の,で区切られたデータの分割\n",
    "#データの並び的に，前側のデータを使えば良さそうだったので，前側のみ抽出\n",
    "def DecomposeStr(x):\n",
    "    if type(x) in (str, object):\n",
    "        point = x.find(\",\")\n",
    "        \n",
    "        if point != -1:\n",
    "            x = x[:point]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16進数を10進数に\n",
    "def HEX2DN(x):\n",
    "    \n",
    "    if x != x:  #NANの場合\n",
    "        return x\n",
    "    else:\n",
    "        x = str(x)\n",
    "        \n",
    "        point = x.find(\".\")\n",
    "        if point != -1:\n",
    "            x = x[:point]\n",
    "        \n",
    "        return int(x, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA組付工程\n",
    "def CreateSABaseData(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.arange(11, 17)\n",
    "    \n",
    "    #読み込む列\n",
    "    #\"chip_id\",\"assy_lot\", \"assy_hinban\",は16番でNGのものはNAになっているので，省いた\n",
    "    col_output  = [\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\",\n",
    "                   \"格納位置_14\", \"格納時間_14\", \"排出時間_14\", \"不良カテゴリ_16\"]\n",
    "    col_rename  = {\"格納位置_14\": \"storage_loc_14\",\n",
    "                   \"格納時間_14\": \"storage_start_14\",\n",
    "                   \"排出時間_14\": \"storage_end_14\",\n",
    "                   \"不良カテゴリ_16\": \"defective_cat_16\"}\n",
    "    col_process = col_others + col_output\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "        \n",
    "    df[\"storage_start_14\"] = pd.to_datetime(df[\"storage_start_14\"])\n",
    "    df[\"storage_end_14\"]   = pd.to_datetime(df[\"storage_end_14\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    for i in pro_no[:-1]:\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, i+1)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(i+1)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    df[\"cure_time[s]\"] = df[[\"storage_start_14\", \"storage_end_14\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #基板ロットが1セルに複数入っているのを分割\n",
    "    df[\"kiban_lot\"] = df[\"kiban_lot\"].map(DecomposeStr)\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    #不良ファイルから，基板品番→基板ロット情報抽出\n",
    "    #定義＆読み込み\n",
    "    sub_cols=[\"sub%s\" %i for i in [1,2,3,4]]\n",
    "    df_sub = pd.read_csv(os.path.join(\"..\", \"SA_DefectiveRatio.csv\"))\n",
    "    df_sub_lot = pd.DataFrame(index=[], columns=sub_cols)\n",
    "    print(df_sub.info())\n",
    "    #1行ずつ，ヒットする基板Noを抽出\n",
    "    for i in np.arange(df.shape[0]):\n",
    "        \n",
    "        sub_lot = df_sub[df_sub[\"Lot\"].astype(str) == df.loc[i, \"kiban_lot\"]]\n",
    "\n",
    "        if len(sub_lot) == 0:\n",
    "            sub_ser = pd.Series([np.nan, np.nan, np.nan, np.nan], index=df_sub_lot.columns)\n",
    "        else:\n",
    "            sub_ser = sub_lot.loc[:, sub_cols]\n",
    "        df_sub_lot = df_sub_lot.append(sub_ser, ignore_index=True)\n",
    "\n",
    "    #大元のファイルと結合\n",
    "    df = pd.concat([df, df_sub_lot], axis=1)\n",
    "   \n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"SA_Sub_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assy基板接着\n",
    "def CreateAssyBaseData(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.arange(32, 34)\n",
    "    \n",
    "    #読み込む列\n",
    "    #\"chip_id\",\"assy_lot\", \"assy_hinban\",は16番でNGのものはNAになっているので，省いた\n",
    "    col_out  = [\"out_put_time_16\"]+[\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\", \"assy_lot\", \"assy_hinban\",\n",
    "                   \"格納位置_14\", \"格納時間_14\", \"排出時間_14\", \"不良カテゴリ_16\",\n",
    "                   \"格納位置_33\", \"格納時間(YYMM)_33\", \"排出時間(YYMM)_33\", \"自動外観結果（1＝OK,2=NG)_33\",\n",
    "                   \"シミ面積Aエリア2_33\", \"シミ面積Bエリア2_33\"]\n",
    "    \n",
    "    col_rename  = {\"格納位置_14\": \"storage_loc_14\",\n",
    "                   \"格納時間_14\": \"storage_start_14\",\n",
    "                   \"排出時間_14\": \"storage_end_14\",\n",
    "                   \"不良カテゴリ_16\": \"defective_cat_16\",\n",
    "                   \"格納位置_33\": \"storage_loc_33\",\n",
    "                   \"格納時間(YYMM)_33\": \"storage_start_33\",\n",
    "                   \"排出時間(YYMM)_33\": \"storage_end_33\",\n",
    "                   \"自動外観結果（1＝OK,2=NG)_33\": \"visual_inspection_33\",\n",
    "                   \"シミ面積Aエリア2_33\": \"blot_areaA_33\", \n",
    "                   \"シミ面積Bエリア2_33\": \"blot_areaB_33\"}\n",
    "    \n",
    "    col_process = col_others + col_out\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "    for i in [14, 33]:\n",
    "        df[\"storage_start_%s\" %i] = pd.to_datetime(df[\"storage_start_%s\" %i])\n",
    "        df[\"storage_end_%s\" %i]   = pd.to_datetime(df[\"storage_end_%s\" %i])\n",
    "    df[\"out_put_time_16\"] = pd.to_datetime(df[\"out_put_time_16\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    df[\"ti_16_to_32[s]\"] = df[[\"out_put_time_16\", \"out_put_time_32\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    for (i, j) in zip(pro_no[:-1], pro_no[1:]):\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, j)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(j)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    for i in [14, 33]:\n",
    "        df[\"cure_time_%s[s]\" %i] = df[[\"storage_start_%s\" %i, \"storage_end_%s\" %i]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "    \"\"\"\n",
    "    #不良ファイルから，基板品番→基板ロット情報抽出\n",
    "    df_sub = pd.read_csv(os.path.join(\"..\", \"SA_DefectiveRatio.csv\"))\n",
    "    df_sub_lot = pd.DataFrame(index=[], columns=[\"Sub%s\" %i for i in [1,2,3,4]])\n",
    "    \n",
    "    for i in np.arange(df.shape[0]):\n",
    "        sub_lot = df_sub[df_sub[\"Lot\"].astype(str) == df.loc[i, \"kiban_lot\"]]\n",
    "        print(sub_lot)\n",
    "        if len(sub_lot) == 0:\n",
    "            sub_lot = [np.nan, np.nan. np.nan, np.nan]\n",
    "        else:\n",
    "            sub_lot = sub_lot.loc[:, [\"Sub%s\" %i for i in [1,2,3,4]]]\n",
    "        df_sub_lot = pd.concat([df_sub_lot, sub_lot])\n",
    "    \n",
    "    df = pd.concat([df, df_sub_lot], axis=1)\n",
    "    \"\"\"\n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"Assy_Sub_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assyゲル気泡\n",
    "def CreateAssyBaseDataWithGel(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.append(np.arange(16, 17), np.arange(32, 38))\n",
    "    \n",
    "    #読み込む列\n",
    "    col_out     = [\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\", \"assy_lot\", \"assy_hinban\",\n",
    "                   \"基板高さ(L)_a_32\", \"基板高さ(L)_b_32\", \"基板高さ(R)_a_32\", \"基板高さ(R)_b_32\", \n",
    "                   \"格納位置_33\", \"格納時間(YYMM)_33\", \"排出時間(YYMM)_33\", \"自動外観結果（1＝OK,2=NG)_33\",\n",
    "                   \"シミ面積Aエリア2_33\", \"シミ面積Bエリア2_33\", \"レーザ除去痕（1＝あり、2＝なし）_33\",\n",
    "                   \"ゲル注入量（プランジャストローク）_a_35\", \"ゲル注入量（プランジャストローク）_b_35\",\n",
    "                   \"基板高さ_a_35\", \"基板高さ_b_35\", \"硬化前ゲル厚_a_35\", \"硬化前ゲル厚_b_35\", \n",
    "                   \"格納位置_36\", \"格納時間(YYMM)_36\", \"排出時間(YYMM)_36\", \"不良カテゴリ_37\",\n",
    "                   \"硬化後ゲル厚1_a_37\", \"硬化後ゲル厚1_b_37\", \"硬化後ゲル厚2_a_37\", \"硬化後ゲル厚2_b_37\", \n",
    "                   \"硬化後ゲル厚3_a_37\", \"硬化後ゲル厚3_b_37\", \"号機_37\"]\n",
    "    \n",
    "    col_rename  = {\"基板高さ(L)_a_32\":\"base_height_L_a_32\",\n",
    "                   \"基板高さ(L)_b_32\":\"base_height_L_b_32\",\n",
    "                   \"基板高さ(R)_a_32\":\"base_height_R_a_32\",\n",
    "                   \"基板高さ(R)_b_32\":\"base_height_R_b_32\",\n",
    "                   \"格納位置_33\":\"storage_loc_33\",\n",
    "                   \"格納時間(YYMM)_33\":\"storage_start_33\",\n",
    "                   \"排出時間(YYMM)_33\":\"storage_end_33\",\n",
    "                   \"自動外観結果（1＝OK,2=NG)_33\":\"visual_inspection_33\",\n",
    "                   \"シミ面積Aエリア2_33\":\"blot_areaA_33\", \n",
    "                   \"シミ面積Bエリア2_33\":\"blot_areaB_33\", \n",
    "                   \"レーザ除去痕（1＝あり、2＝なし）_33\":\"LASER_abl_mark_33\",\n",
    "                   \"ゲル注入量（プランジャストローク）_a_35\":\"gel_plunger_stroke_a_35\",\n",
    "                   \"ゲル注入量（プランジャストローク）_b_35\":\"gel_plunger_stroke_b_35\",\n",
    "                   \"基板高さ_a_35\":\"base_height_a_35\",\n",
    "                   \"基板高さ_b_35\":\"base_height_b_35\",\n",
    "                   \"硬化前ゲル厚_a_35\":\"gel_thick_b4_a_35\",\n",
    "                   \"硬化前ゲル厚_b_35\":\"gel_thick_b4_b_35\",\n",
    "                   \"格納位置_36\":\"storage_loc_36\",\n",
    "                   \"格納時間(YYMM)_36\":\"storage_start_36\",\n",
    "                   \"排出時間(YYMM)_36\":\"storage_end_36\",\n",
    "                   \"不良カテゴリ_37\":\"defective_cat_37\",\n",
    "                   \"硬化後ゲル厚1_a_37\":\"gel_thick1_aft_a_37\",\n",
    "                   \"硬化後ゲル厚1_b_37\":\"gel_thick1_aft_b_37\",\n",
    "                   \"硬化後ゲル厚2_a_37\":\"gel_thick2_aft_a_37\",\n",
    "                   \"硬化後ゲル厚2_b_37\":\"gel_thick2_aft_b_37\",\n",
    "                   \"硬化後ゲル厚3_a_37\":\"gel_thick3_aft_a_37\",\n",
    "                   \"硬化後ゲル厚3_b_37\":\"gel_thick3_aft_b_37\",\n",
    "                   \"号機_37\":\"machine_no_37\"}\n",
    "    \n",
    "    col_process = col_others + col_out\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "    \n",
    "    df[\"storage_start_33\"] = pd.to_datetime(df[\"storage_start_33\"])\n",
    "    df[\"storage_end_33\"]   = pd.to_datetime(df[\"storage_end_33\"])\n",
    "    df[\"out_put_time_16\"] = pd.to_datetime(df[\"out_put_time_16\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    df[\"ti_16_to_32[s]\"] = df[[\"out_put_time_16\", \"out_put_time_32\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    for (i, j) in zip(pro_no[:-1], pro_no[1:]):\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, j)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(j)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    df[\"cure_time_33[s]\"] = df[[\"storage_start_33\", \"storage_end_33\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #ゲルに関する16進数を10進数に変換\n",
    "#    for (drct, alph) in itertools.product([\"L\", \"R\"], [\"a\", \"b\"]):\n",
    "#        df[\"base_height_%s_%s_32\" %(drct, alph)] = df[\"base_height_%s_%s_32\" %(drct, alph)].map(HEX2DN)\n",
    "        \n",
    "    for alph in [\"a\", \"b\"]:\n",
    "        df[\"gel_plunger_stroke_%s_35\" %alph] = df[\"gel_plunger_stroke_%s_35\" %alph].map(HEX2DN)\n",
    "        df[\"base_height_%s_35\" %alph] = df[\"base_height_%s_35\" %alph].map(HEX2DN)\n",
    "        df[\"gel_thick_b4_%s_35\" %alph] = df[\"base_height_%s_35\" %alph].map(HEX2DN) / 100  #定義\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "\n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"AssyWithGel_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA + Assy基板接着\n",
    "def CreateAllBaseData(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.append(np.arange(11, 17), np.arange(32, 34)) #31は当てにならないの\n",
    "    \n",
    "    #読み込む列\n",
    "    #\"chip_id\",\"assy_lot\", \"assy_hinban\",は16番でNGのものはNAになっているので，省いた\n",
    "    col_out  = [\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\", \"assy_lot\", \"assy_hinban\",\n",
    "                   \"格納位置_14\", \"格納時間_14\", \"排出時間_14\", \"不良カテゴリ_16\",\n",
    "                   \"格納位置_33\", \"格納時間(YYMM)_33\", \"排出時間(YYMM)_33\", \"自動外観結果（1＝OK,2=NG)_33\",\n",
    "                   \"シミ面積Aエリア2_33\", \"シミ面積Bエリア2_33\"]\n",
    "    \n",
    "    col_rename  = {\"格納位置_14\": \"storage_loc_14\",\n",
    "                   \"格納時間_14\": \"storage_start_14\",\n",
    "                   \"排出時間_14\": \"storage_end_14\",\n",
    "                   \"不良カテゴリ_16\": \"defective_cat_16\",\n",
    "                   \"格納位置_33\": \"storage_loc_33\",\n",
    "                   \"格納時間(YYMM)_33\": \"storage_start_33\",\n",
    "                   \"排出時間(YYMM)_33\": \"storage_end_33\",\n",
    "                   \"自動外観結果（1＝OK,2=NG)_33\": \"visual_inspection_33\",\n",
    "                   \"シミ面積Aエリア2_33\": \"blot_areaA_33\", \n",
    "                   \"シミ面積Bエリア2_33\": \"blot_areaB_33\"}\n",
    "    \n",
    "    col_process = col_others + col_out\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "    for i in [14, 33]:\n",
    "        df[\"storage_start_%s\" %i] = pd.to_datetime(df[\"storage_start_%s\" %i])\n",
    "        df[\"storage_end_%s\" %i]   = pd.to_datetime(df[\"storage_end_%s\" %i])\n",
    "    df[\"out_put_time_16\"] = pd.to_datetime(df[\"out_put_time_16\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    for (i, j) in zip(pro_no[:-1], pro_no[1:]):\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, j)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(j)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    for i in [14, 33]:\n",
    "        df[\"cure_time_%s[s]\" %i] = df[[\"storage_start_%s\" %i, \"storage_end_%s\" %i]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #基板ロットが1セルに複数入っているのを分割\n",
    "    df[\"kiban_lot\"] = df[\"kiban_lot\"].map(DecomposeStr)\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    #不良ファイルから，基板品番→基板ロット情報抽出\n",
    "    #定義＆読み込み\n",
    "    sub_cols=[\"sub%s\" %i for i in [1,2,3,4]]\n",
    "    df_sub = pd.read_csv(os.path.join(\"..\", \"SA_DefectiveRatio.csv\"))\n",
    "    df_sub_lot = pd.DataFrame(index=[], columns=sub_cols)\n",
    "    \n",
    "    #1行ずつ，ヒットする基板Noを抽出\n",
    "    for i in np.arange(df.shape[0]):\n",
    "        \n",
    "        sub_lot = df_sub[df_sub[\"Lot\"].astype(str) == df.loc[i, \"kiban_lot\"]]\n",
    "\n",
    "        if len(sub_lot) == 0:\n",
    "            sub_ser = pd.Series([np.nan, np.nan, np.nan, np.nan], index=df_sub_lot.columns)\n",
    "        else:\n",
    "            sub_ser = sub_lot.loc[:, sub_cols]\n",
    "        df_sub_lot = df_sub_lot.append(sub_ser, ignore_index=True)\n",
    "\n",
    "    #大元のファイルと結合\n",
    "    df = pd.concat([df, df_sub_lot], axis=1)\n",
    "   \n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"All_Sub_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OK, NGファイルを結合\n",
    "def CreateConcatCSV(csv_files):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        reader = pd.read_csv(os.path.join(w_path, csv_file), low_memory=False, chunksize=2000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "        \n",
    "        if i == 0:\n",
    "            df_res = pd.DataFrame(index=[], columns=df.columns)\n",
    "            pro = csv_file.find(\"_\")\n",
    "            \n",
    "        df_res = pd.concat([df_res, df])\n",
    "        i += 1\n",
    "        \n",
    "    #df_res = df_res.dropna()\n",
    "    df_res = df_res.sort_values(\"sa_lot\")\n",
    "    \n",
    "    df_res.to_csv(os.path.join(w_path, \"Concat_\" + csv_file[:pro] + \"_files.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　MainProgram　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義\n",
    "r_path = os.path.join(\"..\", \"AssemblyData\", \"Original\")\n",
    "w_path = os.path.join(\"..\", \"AssemblyData\", \"Extract_Gel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#オリジナルのファイルから，必要部を抜き出し\n",
    "def GetExtractedData():\n",
    "    csv_files = GetCSVFiles()\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        #CreateSABaseData(csv_file)\n",
    "        #CreateAssyBaseData(csv_file)\n",
    "        #CreateAllBaseData(csv_file)\n",
    "        CreateAssyBaseDataWithGel(csv_file)\n",
    "    \n",
    "    #sa_files = GetSAExtractedFiles()\n",
    "    #CreateConcatCSV(sa_files)\n",
    "    \n",
    "    #assy_files = GetAssyExtractedFiles()\n",
    "    #CreateConcatCSV(assy_files)\n",
    "    \n",
    "    assy_with_gel_files = GetAssyWithGelExtractedFiles()\n",
    "    CreateConcatCSV(assy_with_gel_files)\n",
    "    \n",
    "    #all_files = GetAllExtractedFiles()\n",
    "    #CreateConcatCSV(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetExtractedData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　確認　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　バックアップ　■■■■■"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#基板ロットを入れない場合\n",
    "def CreateSABaseData(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.arange(11, 17)\n",
    "    \n",
    "    #読み込む列\n",
    "    #\"chip_id\",\"assy_lot\", \"assy_hinban\",は16番でNGのものはNAになっているので，省いた\n",
    "    col_output  = [\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\",\n",
    "                   \"格納位置_14\", \"格納時間_14\", \"排出時間_14\", \"不良カテゴリ_16\"]\n",
    "    col_rename  = {\"格納位置_14\": \"storage_loc_14\",\n",
    "                   \"格納時間_14\": \"storage_start_14\",\n",
    "                   \"排出時間_14\": \"storage_end_14\",\n",
    "                   \"不良カテゴリ_16\": \"defective_cat_16\"}\n",
    "    col_process = col_others + col_output\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "        \n",
    "    df[\"storage_start_14\"] = pd.to_datetime(df[\"storage_start_14\"])\n",
    "    df[\"storage_end_14\"]   = pd.to_datetime(df[\"storage_end_14\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    for i in pro_no[:-1]:\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, i+1)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(i+1)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #for i in pro_no[:-1]:\n",
    "    #    for j in pro_no[1:]:\n",
    "    #        if i < j:\n",
    "    #            df[\"ti_%s_%s[s]\" %(i, j)] = (df[\"out_put_time_%s\" %(j)] - df[\"out_put_time_%s\" %(i)]).dt.seconds\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    df[\"cure_time[s]\"] = df[[\"storage_start_14\", \"storage_end_14\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "   \n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"SA_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def CreateAssyBaseData(csv_file):\n",
    "    \n",
    "    #工程番号\n",
    "    pro_no = np.arange(32, 34)\n",
    "    \n",
    "    #読み込む列\n",
    "    #\"chip_id\",\"assy_lot\", \"assy_hinban\",は16番でNGのものはNAになっているので，省いた\n",
    "    col_out  = [\"out_put_time_16\"]+[\"out_put_time_%s\"%i for i in pro_no]\n",
    "    col_others  = [\"sa_lot\", \"sa_seri\", \"sa_hinban\", \"kiban_lot\", \"film_lot\", \"assy_lot\", \"assy_hinban\",\n",
    "                   \"格納位置_14\", \"格納時間_14\", \"排出時間_14\", \"不良カテゴリ_16\",\n",
    "                   \"格納位置_33\", \"格納時間(YYMM)_33\", \"排出時間(YYMM)_33\", \"自動外観結果（1＝OK,2=NG)_33\",\n",
    "                   \"シミ面積Aエリア2_33\", \"シミ面積Bエリア2_33\"]\n",
    "    \n",
    "    col_rename  = {\"格納位置_14\": \"storage_loc_14\",\n",
    "                   \"格納時間_14\": \"storage_start_14\",\n",
    "                   \"排出時間_14\": \"storage_end_14\",\n",
    "                   \"不良カテゴリ_16\": \"defective_cat_16\",\n",
    "                   \"格納位置_33\": \"storage_loc_33\",\n",
    "                   \"格納時間(YYMM)_33\": \"storage_start_33\",\n",
    "                   \"排出時間(YYMM)_33\": \"storage_end_33\",\n",
    "                   \"自動外観結果（1＝OK,2=NG)_33\": \"visual_inspection_33\",\n",
    "                   \"シミ面積Aエリア2_33\": \"blot_areaA_33\", \n",
    "                   \"シミ面積Bエリア2_33\": \"blot_areaB_33\"}\n",
    "    \n",
    "    col_process = col_others + col_out\n",
    "    \n",
    "    #指定工程Noのデータ読み込み\n",
    "    with codecs.open(os.path.join(r_path, csv_file), \"r\", \"Shift-JIS\", \"ignore\") as f:\n",
    "        reader = pd.read_table(f, delimiter=\",\", low_memory=False, usecols=col_process, chunksize=1000)\n",
    "        df = pd.concat((r for r in reader), ignore_index=True)\n",
    "\n",
    "    #列名をリネーム\n",
    "    df = df.rename(columns=col_rename)\n",
    "    \n",
    "    #日付：オブジェクト　→　datetimeへ変換\n",
    "    for i in pro_no:\n",
    "        df[\"out_put_time_%s\" %i] = pd.to_datetime(df[\"out_put_time_%s\" %i])\n",
    "    for i in [14, 33]:\n",
    "        df[\"storage_start_%s\" %i] = pd.to_datetime(df[\"storage_start_%s\" %i])\n",
    "        df[\"storage_end_%s\" %i]   = pd.to_datetime(df[\"storage_end_%s\" %i])\n",
    "    df[\"out_put_time_16\"] = pd.to_datetime(df[\"out_put_time_16\"])\n",
    "    \n",
    "    #工程間の時間　秒\n",
    "    df[\"ti_16_to_32[s]\"] = df[[\"out_put_time_16\", \"out_put_time_32\"]].apply(CalcDeltaSeconds, axis=1)\n",
    "    for (i, j) in zip(pro_no[:-1], pro_no[1:]):\n",
    "        df[\"ti_%s_to_%s[s]\" %(i, j)] = df[[\"out_put_time_%s\" %(i), \"out_put_time_%s\" %(j)]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #マンション在宅時間　秒\n",
    "    for i in [14, 33]:\n",
    "        df[\"cure_time_%s[s]\" %i] = df[[\"storage_start_%s\" %i, \"storage_end_%s\" %i]].apply(CalcDeltaSeconds, axis=1)\n",
    "    \n",
    "    #先にドロップすると，色んな行のNAにヒットしてデータがほぼなくなるので注意\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    #不良ファイルから，基板品番→基板ロット情報抽出\n",
    "    #定義＆読み込み\n",
    "    sub_cols=[\"sub%s\" %i for i in [1,2,3,4]]\n",
    "    df_sub = pd.read_csv(os.path.join(\"..\", \"SA_DefectiveRatio.csv\"))\n",
    "    df_sub_lot = pd.DataFrame(index=[], columns=sub_cols)\n",
    "\n",
    "    #1行ずつ，ヒットする基板Noを抽出\n",
    "    for i in np.arange(df.shape[0]):\n",
    "        sub_lot = df_sub[df_sub[\"Lot\"].astype(str) == df.loc[i, \"kiban_lot\"]]\n",
    "            \n",
    "        if len(sub_lot) == 0:\n",
    "            sub_ser = pd.Series([np.nan, np.nan, np.nan, np.nan], index=df_sub_lot.columns)\n",
    "        else:\n",
    "            sub_ser = sub_lot.loc[:, sub_cols]\n",
    "        df_sub_lot = df_sub_lot.append(sub_ser, ignore_index=True)\n",
    "\n",
    "    #大元のファイルと結合\n",
    "    df = pd.concat([df, df_sub_lot], axis=1)\n",
    "    \n",
    "    #書き出し\n",
    "    df.to_csv(os.path.join(w_path, \"Assy_Sub_\" + csv_file), index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
