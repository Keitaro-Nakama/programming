{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#シミは数値\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　関数　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=600):\n",
    "   \n",
    "    images_path = os.path.join(\"..\", \"Images\")\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    file_name = os.path.join(images_path, fig_id + \".\" + fig_extension)\n",
    "    \n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(file_name, format=fig_extension, dpi=resolution)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConcatSubAssyFiles(r_path):\n",
    "    files = os.listdir(r_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if(file.find(\".csv\") != -1 and file.upper().startswith(\"CONCAT\") and file.find(\"SA\") != -1):\n",
    "            csv_files.append(file)\n",
    "            \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConcatAssyFiles(r_path):\n",
    "    files = os.listdir(r_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if (file.find(\".csv\") != -1 and file.upper().startswith(\"CONCAT\") and file.find(\"Assy\") != -1):\n",
    "            csv_files.append(file)\n",
    "            \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConcatAllFiles(r_path):\n",
    "    files = os.listdir(r_path)\n",
    "    csv_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if (file.find(\".csv\") != -1 and file.upper().startswith(\"CONCAT\") and file.find(\"All\") != -1):\n",
    "            csv_files.append(file)\n",
    "            \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#工程間時間\n",
    "def PrepareFittingData(csv_file):\n",
    "    \n",
    "    #IntervalCSV読み込み\n",
    "    #df = pd.read_csv(os.path.join(r_path, csv_file))\n",
    "    reader = pd.read_csv(os.path.join(r_path, csv_file), low_memory=False, chunksize=2000)\n",
    "    df = pd.concat((r for r in reader), ignore_index=True)\n",
    "    \n",
    "    #X, Yとなるデータの抽出\n",
    "    ti_cols = df.columns[df.columns.str.startswith(\"ti_\")].tolist()\n",
    "    ct_cols = df.columns[df.columns.str.startswith(\"cure_\")].tolist()\n",
    "    bl_cols = df.columns[df.columns.str.startswith(\"blot_\")].tolist()\n",
    "    cols = ti_cols + ct_cols + bl_cols\n",
    "    df = df[cols]\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#工程間時間\n",
    "def PrepareAllFittingData(csv_file):\n",
    "    \n",
    "    #IntervalCSV読み込み\n",
    "    #df = pd.read_csv(os.path.join(r_path, csv_file))\n",
    "    reader = pd.read_csv(os.path.join(r_path, csv_file), low_memory=False, chunksize=2000)\n",
    "    df = pd.concat((r for r in reader), ignore_index=True)\n",
    "    \n",
    "    #X, Yとなるデータの抽出\n",
    "    ti_cols = df.columns[df.columns.str.startswith(\"ti_\")].tolist()\n",
    "    ct_cols = df.columns[df.columns.str.startswith(\"cure_\")].tolist()\n",
    "    bl_cols = df.columns[df.columns.str.startswith(\"blot_\")].tolist()\n",
    "    cols = ti_cols + ct_cols + bl_cols\n",
    "    cols.remove(\"cure_time[s]\")\n",
    "    df = df[cols]\n",
    "    \n",
    "    df = df.dropna(subset=cols)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataScaling(X):\n",
    "    scaler = StandardScaler() #scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(reg, X, y):\n",
    "    y_predict = reg.predict(X)\n",
    "    reg_mse = mean_squared_error(y, y_predict)\n",
    "    reg_rmse = np.sqrt(reg_mse)\n",
    "    reg_scores = cross_val_score(reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    result = np.sqrt(-reg_scores)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcCoefficients(reg, flg, columns):\n",
    "    if flg == \"RandomForest\":\n",
    "        feature = reg.feature_importances_\n",
    "        f1 = pd.DataFrame({\"Name\": columns, \"Features\": feature[:]}).sort_values(by=\"Features\", ascending=False)\n",
    "        f2 = f1.loc[:, [\"Name\", \"Features\"]]\n",
    "    else:\n",
    "        f1 = pd.DataFrame({\"Name\": columns, \"Coefficients\": reg.coef_}).sort_values(by=\"Coefficients\", ascending=False)\n",
    "        f2 = f1.loc[:, [\"Name\", \"Coefficients\"]]\n",
    "    \n",
    "    f2.to_csv(os.path.join(w_path, flg+\".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcMethodComparison(csv_file):\n",
    "    \n",
    "    #定義\n",
    "    result = pd.DataFrame()\n",
    "    reg_method = [\"SGD\", \"Lasso\", \"Ridge\", \"ElasticNet\", \"SVR\", \"RandomForest\"]\n",
    "    method, rmse_mean, rmse_dev, corr = [], [], [], []\n",
    "    \n",
    "    #データ準備\n",
    "    df = PrepareAllFittingData(csv_file)\n",
    "    \n",
    "    #学習データ，検証データに分類\n",
    "    train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    #目的変数設定\n",
    "    #obj_cols = [\"defective_cat_16\"] #subassy\n",
    "    obj_cols = [\"blot_area%s_33\" %r for r in [\"A\", \"B\"]]\n",
    "    \n",
    "    X_train  = train_set.drop(columns=obj_cols)\n",
    "    X_test   = test_set.drop(columns=obj_cols)\n",
    "    y_train  = train_set[obj_cols[0]].copy()\n",
    "    y_test   = test_set[obj_cols[0]].copy()\n",
    "    exp_cols = X_train.columns\n",
    "\n",
    "    \n",
    "    #説明変数の標準化\n",
    "    X_train = DataScaling(X_train)\n",
    "    X_test  = DataScaling(X_test)\n",
    "    \n",
    "    plt.figure()\n",
    "    i_mat = 1\n",
    "    \n",
    "    #分類器毎の実力\n",
    "    for flg in reg_method:\n",
    "    \n",
    "        #分類器選択\n",
    "        if flg == \"SGD\":\n",
    "            reg = SGDRegressor(max_iter=1000, penalty=\"l2\", tol=1e-3, random_state=42)            \n",
    "        elif flg == \"Lasso\":\n",
    "            reg = Lasso(alpha=1.0, random_state=42)\n",
    "        elif flg == \"Ridge\":\n",
    "            reg = Ridge(alpha=1.0, solver=\"cholesky\", random_state=42)\n",
    "        elif flg == \"ElasticNet\":\n",
    "            reg = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "        #elif flg == \"SVR\":\n",
    "            #reg = SVR(kernel=\"rbf\")\n",
    "        elif flg == \"RandomForest\":\n",
    "            reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "        else:\n",
    "            print(\"No such a method\")\n",
    "            continue\n",
    "\n",
    "        #学習\n",
    "        if flg == \"SGD\":\n",
    "            reg.fit(X_train, y_train.ravel())\n",
    "        else:\n",
    "            reg.fit(X_train, y_train)\n",
    "        \n",
    "        #予測\n",
    "        y_test_predict = reg.predict(X_test)\n",
    "        \n",
    "        #検証\n",
    "        reg_test_rmse_scores = CrossValidation(reg, X_test, y_test)\n",
    "        \n",
    "        #特徴量抽出\n",
    "        CalcCoefficients(reg, flg, exp_cols)\n",
    "\n",
    "        method.append(flg)\n",
    "        rmse_mean.append(reg_test_rmse_scores.mean())\n",
    "        rmse_dev.append(reg_test_rmse_scores.std())\n",
    "        corr.append(np.corrcoef(y_test, y_test_predict)[0, 1])\n",
    "        \n",
    "        #予測結果プロット\n",
    "        plt.subplot(2, 3, i_mat)\n",
    "        plt.scatter(y_test_predict, y_test, color=\"black\", marker=\"o\", s=5, alpha=0.3)\n",
    "        plt.plot([0, 2500],[0, 2500], color=\"gray\", linestyle=\"-\", linewidth=0.5)  \n",
    "        plt.xlabel(\"Predicted\", fontsize=8)\n",
    "        plt.ylabel(\"Measured\", fontsize=8)\n",
    "        plt.title(flg, fontsize=10)\n",
    "        plt.tick_params(labelsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.axis([0, 2500, 0, 2500])\n",
    "        i_mat += 1\n",
    "        \n",
    "        print(flg, \"is done\")\n",
    "\n",
    "    #グラフ保存    \n",
    "    SaveFig(\"Summary\")\n",
    "    \n",
    "    #書き出し\n",
    "    result[\"method\"] = method\n",
    "    result[\"rmse_score\"] = rmse_mean\n",
    "    result[\"rmse_stddev\"] = rmse_dev\n",
    "    result[\"correlation\"] = corr\n",
    "        \n",
    "    result.to_csv(os.path.join(w_path, \"result_\"+csv_file), index=False)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    #モデル評価\n",
    "    y_test_predict = reg.predict(X_test)\n",
    "    y_test_predict = cross_val_predict(reg, X_train, y_train, cv=10, method=\"predict_proba\") #RandomForest\"の場合\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotHistgramInterval(csv_file):\n",
    "    \n",
    "    #IntervalCSV読み込み\n",
    "    df = pd.read_csv(os.path.join(r_path, csv_file))\n",
    "    print(df.describe())\n",
    "    cols = [\"ti_16_to_32[s]\", \"ti_32_to_33[s]\", \"cure_time_33[s]\"]\n",
    "    \n",
    "    #1画像辺りのサブプロット数\n",
    "    plt_row = 3\n",
    "    plt_col = 1\n",
    "    \n",
    "    #figNo設定\n",
    "    i_mat = 0\n",
    "    i_fig = 0\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    for col in cols:\n",
    "        i_mat += 1\n",
    "        \n",
    "        plt.subplot(plt_row, plt_col, i_mat)\n",
    "        plt.hist(df[col].values, bins=100, alpha=0.3, color=\"b\")\n",
    "        \n",
    "        plt.title(col)\n",
    "        plt.tick_params(labelsize=8)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    SaveFig(\"assy_interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　MainProgram　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義\n",
    "r_path = os.path.join(\"..\", \"AssemblyData\", \"Extract\")\n",
    "w_path = os.path.join(\"..\", \"AssemblyData_Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SubAssy\n",
    "#csv_files = GetIntervalCSVFiles(r_path)\n",
    "csv_files = GetConcatSubAssyFiles(r_path)\n",
    "CalcMethodComparison(csv_files[1])\n",
    "GetRFCFeatures(csv_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assyインターバル学習\n",
    "csv_files = GetConcatAssyFiles(r_path)\n",
    "for csv_file in csv_files:\n",
    "    CalcMethodComparison(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ti_11_to_12[s]', 'ti_12_to_13[s]', 'ti_13_to_14[s]', 'ti_14_to_15[s]', 'ti_15_to_16[s]', 'ti_16_to_32[s]', 'ti_32_to_33[s]', 'cure_time_14[s]', 'cure_time_33[s]', 'blot_areaA_33', 'blot_areaB_33']\n",
      "SGD is done\n",
      "Lasso is done\n",
      "Ridge is done\n",
      "ElasticNet is done\n",
      "No such a method\n",
      "RandomForest is done\n",
      "Saving figure Summary\n"
     ]
    }
   ],
   "source": [
    "#Assyインターバル学習 SubAssy時間有り\n",
    "csv_files = GetConcatAllFiles(r_path)\n",
    "for csv_file in csv_files:\n",
    "    CalcMethodComparison(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sa_lot        sa_seri     sa_hinban       assy_lot  \\\n",
      "count  374745.000000  374745.000000  3.747450e+05  374745.000000   \n",
      "mean    97222.006524   10982.054488  4.689100e+09   96673.695814   \n",
      "std        70.418014    6604.124085  0.000000e+00    3606.485985   \n",
      "min     97101.000000       1.000000  4.689100e+09   54321.000000   \n",
      "25%     97161.000000    5473.000000  4.689100e+09   97253.000000   \n",
      "50%     97218.000000   10577.000000  4.689100e+09   97371.000000   \n",
      "75%     97280.000000   16146.000000  4.689100e+09   97501.000000   \n",
      "max     97345.000000   26880.000000  4.689100e+09   98184.000000   \n",
      "\n",
      "        assy_hinban  storage_loc_14  defective_cat_16  storage_loc_33  \\\n",
      "count  3.747450e+05   374745.000000          374745.0   374745.000000   \n",
      "mean   4.689001e+09      806.519342               0.0      100.999872   \n",
      "std    1.580905e+03      431.326028               0.0       58.378961   \n",
      "min    4.689000e+09      101.000000               0.0        1.000000   \n",
      "25%    4.689000e+09      408.000000               0.0       48.000000   \n",
      "50%    4.689000e+09      806.000000               0.0      104.000000   \n",
      "75%    4.689000e+09     1203.000000               0.0      153.000000   \n",
      "max    4.689005e+09     1509.000000               0.0      200.000000   \n",
      "\n",
      "       visual_inspection_33  blot_areaA_33  blot_areaB_33       film_lot  \\\n",
      "count         374745.000000  374745.000000  374745.000000  374745.000000   \n",
      "mean               1.123935      32.318886      11.459713  804031.754767   \n",
      "std                0.329508     154.265483      83.447280     363.610391   \n",
      "min                1.000000       0.000000       0.000000  803186.000000   \n",
      "25%                1.000000       0.000000       0.000000  804187.000000   \n",
      "50%                1.000000       0.000000       0.000000  804188.000000   \n",
      "75%                1.000000       0.000000       0.000000  804189.000000   \n",
      "max                2.000000    2479.000000    2479.000000  804189.000000   \n",
      "\n",
      "       ti_16_to_32[s]  ti_32_to_33[s]  cure_time_14[s]  cure_time_33[s]  \n",
      "count    3.747450e+05   374745.000000    374745.000000    374745.000000  \n",
      "mean     4.750202e+05    10225.415309      9445.588718      9769.085058  \n",
      "std      1.364324e+05    21211.345266     28083.549745     21131.058275  \n",
      "min      1.674370e+05     4365.000000      4294.000000      4139.000000  \n",
      "25%      3.711600e+05     5071.000000      4305.000000      4733.000000  \n",
      "50%      4.663230e+05     5834.000000      4408.000000      5452.000000  \n",
      "75%      5.670050e+05     7991.000000      6216.000000      7475.000000  \n",
      "max      1.075981e+06   197366.000000    284829.000000    197068.000000  \n",
      "Saving figure assy_interval\n"
     ]
    }
   ],
   "source": [
    "PlotHistgramInterval(csv_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　確認　■■■■■"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■■■■■　バックアップ　■■■■■"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#工程間　相互\n",
    "def PrepareFittingData(csv_file):\n",
    "    \n",
    "    #IntervalCSV読み込み\n",
    "    df = pd.read_csv(os.path.join(r_path, csv_file))\n",
    "    \n",
    "    #OK:0, NG:31のデータ抽出 query は　boolインデックスより新しいみたい\n",
    "    df = df.query(\"defective_cat_16 == 0 or defective_cat_16 == 31\") \n",
    "    \n",
    "    #X, Yとなるデータの抽出\n",
    "    cols = df.columns[df.columns.str.startswith(\"ti_\")].tolist()\n",
    "    cols.extend([\"cure_time[s]\", \"defective_cat_16\"])\n",
    "    df = df[cols]\n",
    "    \n",
    "    #NG:31を1に変換\n",
    "    df.loc[df[\"defective_cat_16\"]==31, \"defective_cat_16\"] = 1\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(\"index\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
